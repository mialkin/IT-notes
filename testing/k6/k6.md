# k6

- [k6](#k6)
  - [Install](#install)
  - [Run](#run)
  - [Run Parameters](#run-parameters)
  - [Overview](#overview)
  - [More](#more)

**k6** is a source load testing tool and SaaS for engineering teams.

## Install

```bash
brew install k6
```

## Run

k6 works with the concept of **virtual users** (**VUs**) that execute scripts — they're essentially glorified, parallel `while(true)` loops. Scripts are written using JavaScript as ES6 modules, which allows you to break larger tests into smaller and more reusable pieces, making it easy to scale tests across an organization.

Scripts must contain, at the very least, an exported `default` function — this defines the entry point for your VUs, similar to the `main()` function in many languages:

```js
import http from "k6/http";

export default function() {
    let response = http.get("https://test-api.k6.io");
};
```

Save script as `test1.js` and run:

```bash
k6 run test1.js
```

Output:

<image src="test1.png" />

For metrics explanation see [↑ HTTP-specific built-in metrics](https://k6.io/docs/using-k6/metrics/#http-specific-built-in-metrics).

## Run Parameters

```bash
k6 run --vus 1 --duration 1m --iterations 1 test.js
```

## Overview

Each virtual user (VU) executes your script in a completely separate JavaScript runtime, parallel to all of the other running VUs. Code inside the `default` function is called **VU code** and is run over and over for as long as the test is running. Code outside of the default function is called **init code** and is run only once per VU when that VU is initialized.

VU code can make HTTP and WebSocket requests, emit metrics, and generally do everything you'd expect a load test to do. With a few important exceptions - you can't load anything from your local filesystem or import any other modules. This all has to be done from the init code.

There are two reasons for this. The first is, of course, performance. If you read a file from disk on every single script iteration, it'd be needlessly slow. Even if you cache the contents of the file and any imported modules, it'd mean the *first run* of the script would be much slower than all the others. Worse yet, if you have a script that imports or loads things based on things that can only be known at runtime, you'd get slow iterations thrown in every time you load something new. That's also the reason why we initialize *all* needed VUs before any of them starts the actual load test by executing the `default` function.

But there's another, more interesting reason. By forcing all imports and file reads into the init context, we design for distributed execution. We know which files will be needed, so we distribute only those files to each node in the cluster. We know which modules will be imported, so we can bundle them up in an [↑ archive](https://k6.io/docs/misc/archive-command/) from the get-go. And, tying into the performance point above, the other nodes don't even need writable file systems - everything can be kept in memory.

This means that if your script works when it's executed with `k6 run` locally, it should also work without any modifications in a distributed execution environment like `k6 cloud` (that executes it in the commercial k6 cloud infrastructure) or, in the future, with the planned k6 native cluster execution mode.

## More

More documentation: [↑ https://github.com/grafana/k6](https://github.com/grafana/k6)
